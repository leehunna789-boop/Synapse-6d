import streamlit as st
import os
import librosa
import soundfile as sf
import numpy as np
import torch
import pickle
import matplotlib.pyplot as plt

# --- 1. ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡∏≤‡πÅ‡∏•‡∏∞‡∏ò‡∏µ‡∏° (Black & Red) ---
st.set_page_config(page_title="SYNAPSE 6D PRO", layout="wide")
st.markdown("""
    <style>
    .main { background-color: #000000; color: #ff0000; }
    h1, h2, h3 { color: #ff0000 !important; font-family: 'Courier New', monospace; text-shadow: 2px 2px #550000; }
    .stButton>button { background-color: #ff0000; color: white; width: 100%; font-weight: bold; border-radius: 10px; border: none; }
    .stTextInput>div>div>input { background-color: #1a1a1a; color: #ff0000; border: 1px solid #ff0000; }
    [data-testid="stHeader"] { background: rgba(0,0,0,0); }
    </style>
    """, unsafe_allow_html=True)

# --- 2. ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå .pth (‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏™‡πà‡∏á‡∏°‡∏≤‡∏ï‡∏≠‡∏ô‡πÅ‡∏£‡∏Å) ---
def display_model_info(file_path):
    if not file_path or file_path == "‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå .pth":
        return
    st.subheader("## üîç ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÇ‡∏°‡πÄ‡∏î‡∏• (Model Insight)")
    try:
        # ‡πÉ‡∏ä‡πâ torch.load ‡∏ï‡∏≤‡∏°‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå PyData Viewer ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì
        checkpoint = torch.load(file_path, map_location='cpu')
        col_m1, col_m2 = st.columns(2)
        with col_m1:
            st.write(f"**üì¶ ‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå:** `{os.path.basename(file_path)}`")
            if isinstance(checkpoint, dict) and 'epoch' in checkpoint:
                st.write(f"**‚è≥ ‡∏ù‡∏∂‡∏Å‡∏ù‡∏ô‡∏°‡∏≤‡πÅ‡∏•‡πâ‡∏ß:** {checkpoint['epoch']} Epochs")
        with col_m2:
            st.success("‚úÖ ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")
    except Exception as e:
        st.warning(f"‚ÑπÔ∏è ‡∏≠‡πà‡∏≤‡∏ô Metadata ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ (‡∏≠‡∏≤‡∏à‡πÄ‡∏õ‡πá‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏ö‡∏ö Index): {e}")

# --- 3. ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ß‡∏≤‡∏î‡∏Å‡∏£‡∏≤‡∏ü‡πÄ‡∏™‡∏µ‡∏¢‡∏á ---
def plot_waveform(data, sr, title="Waveform"):
    fig, ax = plt.subplots(figsize=(10, 2.5), facecolor='black')
    ax.plot(np.linspace(0, len(data)/sr, len(data)), data, color='#ff0000', linewidth=0.7)
    ax.set_title(title, color='white', size=10)
    ax.axis('off')
    return fig

# --- 4. ‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠‡∏´‡∏•‡∏±‡∏Å ---
st.title("üß¨ SYNAPSE 6D - AI VOCAL ENGINE")
st.write("---")

col1, col2 = st.columns([1, 1.2])

with col1:
    st.subheader("üî¥ ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÅ‡∏´‡∏•‡πà‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á")
    vocal_file = st.file_uploader("1. ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏û‡∏µ‡∏¢‡∏ß‡πÜ", type=["wav", "mp3"])
    inst_file = st.file_uploader("2. ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏î‡∏ô‡∏ï‡∏£‡∏µ‡πÄ‡∏û‡∏µ‡∏¢‡∏ß‡πÜ", type=["wav", "mp3"])
    
    # ‡∏î‡∏∂‡∏á‡πÑ‡∏ü‡∏•‡πå .pth ‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏°‡∏≤‡πÇ‡∏ä‡∏ß‡πå (‡∏ï‡∏≤‡∏°‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡∏Ñ‡∏∏‡∏ì)
    model_files = [f for f in os.listdir(".") if f.endswith(".pth")]
    selected_model = st.selectbox("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏®‡∏¥‡∏•‡∏õ‡∏¥‡∏ô (.pth):", model_files if model_files else ["‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå .pth"])
    
    # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏±‡∏ô‡∏ó‡∏µ‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å
    if selected_model != "‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå .pth":
        display_model_info(selected_model)
    
    pitch = st.slider("‡∏õ‡∏£‡∏±‡∏ö‡πÇ‡∏ó‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡∏á (Pitch Shift)", -12, 12, 0)

with col2:
    st.subheader("üî¥ ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡∏∞‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•")
    if vocal_file and inst_file:
        # ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö
        y_v, sr = librosa.load(vocal_file, sr=None)
        st.pyplot(plot_waveform(y_v, sr, "Original Vocal Visualizer"))
        
        if st.button("üöÄ EXECUTE SYNAPSE ENGINE"):
            with st.status("‚öôÔ∏è ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÅ‡∏•‡∏∞‡∏°‡∏¥‡∏Å‡∏ã‡πå‡πÄ‡∏û‡∏•‡∏á...", expanded=True) as status:
                # 1. ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á (Pitch Shift Simulation)
                v_transformed = librosa.effects.pitch_shift(y_v, sr=sr, n_steps=pitch)
                
                # 2. ‡πÇ‡∏´‡∏•‡∏î‡∏î‡∏ô‡∏ï‡∏£‡∏µ‡πÅ‡∏•‡∏∞‡∏°‡∏¥‡∏Å‡∏ã‡πå
                y_i, _ = librosa.load(inst_file, sr=sr)
                max_len = max(len(v_transformed), len(y_i))
                final_mix = np.pad(v_transformed, (0, max_len - len(v_transformed))) + \
                            np.pad(y_i, (0, max_len - len(y_i)))
                
                # 3. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å
                output_path = "synapse_master.wav"
                sf.write(output_path, final_mix, sr)
                status.update(label="‚úÖ SYNAPSE Engine: ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!", state="complete")
            
            st.audio(output_path)
            with open(output_path, "rb") as f:
                st.download_button("üì• ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î Master (WAV)", f, file_name="synapse_final.wav")
    else:
        st.info("üí° ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏ó‡∏±‡πâ‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏£‡πâ‡∏≠‡∏á‡πÅ‡∏•‡∏∞‡∏î‡∏ô‡∏ï‡∏£‡∏µ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ó‡∏≥‡∏á‡∏≤‡∏ô")
