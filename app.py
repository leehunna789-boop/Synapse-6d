import streamlit as st
import os
import librosa
import soundfile as sf
import numpy as np
import torch
import parselmouth
import matplotlib.pyplot as plt
import google.generativeai as genai
from edge_tts import Communicate
import asyncio

# --- 1. ‡∏™‡πÑ‡∏ï‡∏•‡πå‡πÅ‡∏•‡∏∞‡∏ò‡∏µ‡∏° (Black & Red) ---
st.set_page_config(page_title="SYNAPSE 6D PRO", layout="wide")
st.markdown("""
    <style>
    .main { background-color: #000000; color: #ff0000; }
    h1, h2, h3 { color: #ff0000 !important; font-family: 'Courier New', monospace; text-shadow: 2px 2px #550000; }
    .stButton>button { background-color: #ff0000; color: white; width: 100%; font-weight: bold; border-radius: 10px; }
    .stTextInput>div>div>input { background-color: #1a1a1a; color: #ff0000; border: 1px solid #ff0000; }
    </style>
    """, unsafe_allow_html=True)

# --- 2. ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÄ‡∏™‡∏£‡∏¥‡∏° (‡∏î‡∏∂‡∏á Library ‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏™‡πà‡∏á‡∏°‡∏≤‡∏°‡∏≤‡πÉ‡∏ä‡πâ) ---
def plot_waveform(data, sr):
    fig, ax = plt.subplots(figsize=(10, 2), facecolor='black')
    ax.plot(np.linspace(0, len(data)/sr, len(data)), data, color='#ff0000', linewidth=0.5)
    ax.axis('off')
    return fig

# --- 3. ‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠‡∏´‡∏•‡∏±‡∏Å ---
st.title("üß¨ SYNAPSE 6D - ALL-IN-ONE AI STUDIO")
st.write("---")

tab1, tab2, tab3 = st.tabs(["üé§ RVC Conversion", "ü§ñ Gemini AI Lyrics", "üó£Ô∏è Text-to-Speech"])

# --- TAB 1: RVC & MIXING (‡∏´‡∏±‡∏ß‡πÉ‡∏à‡∏´‡∏•‡∏±‡∏Å‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì) ---
with tab1:
    col1, col2 = st.columns(2)
    with col1:
        st.subheader("üî¥ Input Sources")
        vocal_file = st.file_uploader("‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏û‡∏µ‡∏¢‡∏ß‡πÜ", type=["wav", "mp3"])
        inst_file = st.file_uploader("‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏î‡∏ô‡∏ï‡∏£‡∏µ‡πÄ‡∏û‡∏µ‡∏¢‡∏ß‡πÜ", type=["wav", "mp3"])
        
        model_files = [f for f in os.listdir(".") if f.endswith(".pth")]
        selected_model = st.selectbox("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Model AI (.pth):", model_files if model_files else ["‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå .pth"])
        
        pitch = st.slider("‡∏õ‡∏£‡∏±‡∏ö Pitch (Semitones)", -12, 12, 0)

    with col2:
        st.subheader("üî¥ Processing & Result")
        if vocal_file and inst_file:
            # ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏î‡πâ‡∏ß‡∏¢ Parselmouth
            st.write("üîç ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö...")
            y, sr = librosa.load(vocal_file, sr=None)
            st.pyplot(plot_waveform(y, sr))
            
            if st.button("üöÄ EXECUTE SYNAPSE ENGINE"):
                with st.status("‚öôÔ∏è ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• RVC...", expanded=True) as status:
                    # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á (Simulated RVC Inference using Pitch Shift)
                    v_transformed = librosa.effects.pitch_shift(y, sr=sr, n_steps=pitch)
                    
                    # ‡∏°‡∏¥‡∏Å‡∏ã‡πå‡∏Å‡∏±‡∏ö‡∏î‡∏ô‡∏ï‡∏£‡∏µ
                    i_data, _ = librosa.load(inst_file, sr=sr)
                    max_len = max(len(v_transformed), len(i_data))
                    final_mix = np.pad(v_transformed, (0, max_len - len(v_transformed))) + \
                                np.pad(i_data, (0, max_len - len(i_data)))
                    
                    output_path = "synapse_master.wav"
                    sf.write(output_path, final_mix, sr)
                    status.update(label="‚úÖ ‡∏ú‡∏•‡∏¥‡∏ï‡πÄ‡∏û‡∏•‡∏á‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!", state="complete")
                
                st.audio(output_path)
                st.download_button("üì• Download Master", open(output_path, "rb"), file_name="synapse_final.wav")

# --- TAB 2: GEMINI AI (‡πÉ‡∏ä‡πâ google-generativeai ‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏™‡πà‡∏á‡∏°‡∏≤) ---
with tab2:
    st.subheader("üìù AI Songwriter (Gemini)")
    user_prompt = st.text_input("‡∏≠‡∏¢‡∏≤‡∏Å‡πÉ‡∏´‡πâ Gemini ‡∏ä‡πà‡∏ß‡∏¢‡πÅ‡∏ï‡πà‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡πÄ‡∏û‡∏•‡∏á‡πÅ‡∏ô‡∏ß‡πÑ‡∏´‡∏ô? (‡πÄ‡∏ä‡πà‡∏ô ‡πÅ‡∏£‡πá‡∏õ‡πÄ‡∏î‡∏∑‡∏≠‡∏î‡πÜ, R&B ‡πÄ‡∏´‡∏á‡∏≤‡πÜ)")
    if st.button("‚úçÔ∏è ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡πÄ‡∏û‡∏•‡∏á"):
        st.write("ü§ñ Gemini ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÅ‡∏ï‡πà‡∏á‡πÄ‡∏û‡∏•‡∏á‡πÉ‡∏´‡πâ‡∏Ñ‡∏∏‡∏ì... (‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏™‡πà API KEY ‡πÉ‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î)")
        # ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏: ‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ genai.configure(api_key="YOUR_KEY") ‡∏ñ‡∏∂‡∏á‡∏à‡∏∞‡∏£‡∏±‡∏ô‡πÑ‡∏î‡πâ‡∏à‡∏£‡∏¥‡∏á

# --- TAB 3: TTS (‡πÉ‡∏ä‡πâ edge-tts ‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏™‡πà‡∏á‡∏°‡∏≤) ---
with tab3:
    st.subheader("üó£Ô∏è AI Voice Generator")
    tts_text = st.text_area("‡πÉ‡∏™‡πà‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏´‡πâ AI ‡∏û‡∏π‡∏î:")
    if st.button("üì¢ Generate Voice"):
        st.info("‡∏£‡∏∞‡∏ö‡∏ö‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏û‡∏π‡∏î‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°...")
        # ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ edge-tts ‡∏à‡∏∞‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ
        if st.button("üöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏™‡∏ß‡∏°‡∏£‡∏≠‡∏¢‡πÄ‡∏™‡∏µ‡∏¢‡∏á RVC"):
            if vocal_file and inst_file:
                with st.status("üî¥ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£ SYNAPSE Engine...", expanded=True) as status:
                    
                    # 1. ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏™‡∏µ‡∏¢‡∏á (Backend Processing)
                    st.write("üì• ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ñ‡∏•‡∏∑‡πà‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡∏á...")
                    y_vocal, sr = librosa.load(vocal_file, sr=None)
                    y_inst, _ = librosa.load(inst_file, sr=sr)
                    
                    # 2. ‡∏õ‡∏£‡∏±‡∏ö‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á AI (Pitch Shift)
                    # ‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏£‡πâ‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡πÉ‡∏´‡πâ‡∏Å‡∏•‡∏≤‡∏¢‡πÄ‡∏õ‡πá‡∏ô‡πÇ‡∏ó‡∏ô‡∏Ç‡∏≠‡∏á‡∏®‡∏¥‡∏•‡∏õ‡∏¥‡∏ô
                    st.write(f"üé≠ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏ß‡∏°‡∏£‡∏≠‡∏¢‡πÄ‡∏™‡∏µ‡∏¢‡∏á (Pitch: {pitch})")
                    vocal_ai = librosa.effects.pitch_shift(y_vocal, sr=sr, n_steps=pitch)
                    
                    # 3. ‡∏Å‡∏≤‡∏£‡∏£‡∏ß‡∏°‡∏£‡πà‡∏≤‡∏á (Mixing)
                    st.write("üéπ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏°‡∏¥‡∏Å‡∏ã‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á AI ‡πÄ‡∏Ç‡πâ‡∏≤‡∏Å‡∏±‡∏ö‡∏î‡∏ô‡∏ï‡∏£‡∏µ‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö...")
                    # ‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡πÉ‡∏´‡πâ‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ô
                    max_len = max(len(vocal_ai), len(y_inst))
                    vocal_final = np.pad(vocal_ai, (0, max_len - len(vocal_ai)))
                    inst_final = np.pad(y_inst, (0, max_len - len(y_inst)))
                    
                    # ‡∏£‡∏ß‡∏°‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏Ç‡πâ‡∏≤‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô
                    final_song = vocal_final + inst_final
                    
                    # 4. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
                    output_name = "synapse_final_master.wav"
                    sf.write(output_name, final_song, sr)
                    
                    status.update(label="‚úÖ ‡∏°‡∏¥‡∏Å‡∏ã‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á AI ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå!", state="complete")
                    
                    # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏á‡∏≤‡∏ô‡∏ä‡∏¥‡πâ‡∏ô‡πÇ‡∏ö‡πÅ‡∏î‡∏á
                    st.divider()
                    st.subheader("## üéß ‡∏ú‡∏•‡∏á‡∏≤‡∏ô‡∏ä‡∏¥‡πâ‡∏ô‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢ (Final Master)")
                    st.audio(output_name)
                    
                    # ‡∏õ‡∏∏‡πà‡∏°‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î (‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏î‡∏ß‡∏Å)
                    with open(output_name, "rb") as file:
                        st.download_button(
                            label="üì• ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏û‡∏•‡∏á‡∏ô‡∏µ‡πâ",
                            data=file,
                            file_name="synapse_ai_song.wav",
                            mime="audio/wav"
                        )
            else:
                st.error("‚ö†Ô∏è ‡∏û‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏™‡πà‡∏ó‡∏±‡πâ‡∏á '‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏£‡πâ‡∏≠‡∏á' ‡πÅ‡∏•‡∏∞ '‡∏î‡∏ô‡∏ï‡∏£‡∏µ' ‡∏ô‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö ‡πÑ‡∏°‡πà‡∏á‡∏±‡πâ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö‡∏£‡∏±‡∏ô‡∏ï‡πà‡∏≠‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ!")
import pickle
import torch

def display_model_info(file_path):
    st.subheader("## üîç ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏™‡πÄ‡∏õ‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏• (Model Inspection)")
    try:
        # ‡πÉ‡∏ä‡πâ‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏≤‡∏£‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏™‡πà‡∏á‡∏°‡∏≤ ‡πÅ‡∏ï‡πà‡∏õ‡∏£‡∏±‡∏ö‡πÉ‡∏´‡πâ‡πÄ‡∏Ç‡πâ‡∏≤‡∏Å‡∏±‡∏ö RVC (.pth)
        checkpoint = torch.load(file_path, map_location='cpu')
        
        col_m1, col_m2 = st.columns(2)
        with col_m1:
            st.write(f"**üì¶ ‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå:** `{os.path.basename(file_path)}`")
            # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏• RVC ‡∏õ‡∏Å‡∏ï‡∏¥‡∏à‡∏∞‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Epochs
            if 'epoch' in checkpoint:
                st.write(f"**‚è≥ ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô (Epochs):** {checkpoint['epoch']}")
        
        with col_m2:
            st.write(f"**ü§ñ ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•:** `torch.Tensor` / `RVC Model` ")
            st.success("‚úÖ ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ô‡∏µ‡πâ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏ß‡∏°‡∏£‡∏≠‡∏¢‡πÄ‡∏™‡∏µ‡∏¢‡∏á")
            
    except Exception as e:
        st.error(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏î‡πâ: {e}")

# ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏£‡∏¥‡πà‡∏° Convert
if selected_pth:
    display_model_info(selected_pth)

